<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Jake Thompson</title>
    <link>https://wjakethompson.github.io/post/</link>
    <description>Recent content in Posts on Jake Thompson</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 W. Jake Thompson</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/post/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Recreating the Datasaurus Dozen Using tweenr and ggplot2</title>
      <link>https://wjakethompson.github.io/post/datasaurus-dozen/</link>
      <pubDate>Fri, 05 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://wjakethompson.github.io/post/datasaurus-dozen/</guid>
      <description>&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;


&lt;p&gt;If you haven’t seen it yet, there’s a great example of why it’s always important to visualize your data making its way around the Twitter-verse.&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;en&#34;&gt;
&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;
A great demonstration of why we need to plot the data and never trust statistics tables! &lt;a href=&#34;https://t.co/JyUb57v0or&#34;&gt;https://t.co/JyUb57v0or&lt;/a&gt; &lt;a href=&#34;https://t.co/hsivGZdpZ1&#34;&gt;pic.twitter.com/hsivGZdpZ1&lt;/a&gt;
&lt;/p&gt;
— Taha Yasseri (&lt;span class=&#34;citation&#34;&gt;@TahaYasseri&lt;/span&gt;) &lt;a href=&#34;https://twitter.com/TahaYasseri/status/859084459127316480&#34;&gt;May 1, 2017&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;Despite looking very different, all of these datasets have the same summary statistics to two decimal places. You can download the datasets, get details about the project, and read the whole paper by Justin Matejka and George Fitzmaurice &lt;a href=&#34;https://www.autodeskresearch.com/publications/samestats&#34;&gt;here&lt;/a&gt;. In this post, I’ll show how we can recreate the GIF from the above tweet using &lt;a href=&#34;https://github.com/thomasp85/tweenr&#34;&gt;&lt;strong&gt;tweenr&lt;/strong&gt;&lt;/a&gt; and &lt;a href=&#34;https://github.com/dgrtwo/gganimate&#34;&gt;&lt;strong&gt;gganimate&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;creating-the-plots&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Creating the plots&lt;/h2&gt;
&lt;p&gt;The first step is to read in the data. The data has three variables: the dataset name, x, and y. I’ll define dataset as a factor so that the datasets will appear in the correct order in the animation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(forcats)

datasaurus &amp;lt;- read_table2(&amp;quot;datafiles/DatasaurusDozen.tsv&amp;quot;,
  col_names = TRUE, col_types = &amp;quot;cnn&amp;quot;) %&amp;gt;%
  mutate(dataset = as_factor(dataset))
datasaurus
#&amp;gt; # A tibble: 1,846 x 3
#&amp;gt;    dataset       x       y
#&amp;gt;     &amp;lt;fctr&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
#&amp;gt;  1    dino 55.3846 97.1795
#&amp;gt;  2    dino 51.5385 96.0256
#&amp;gt;  3    dino 46.1538 94.4872
#&amp;gt;  4    dino 42.8205 91.4103
#&amp;gt;  5    dino 40.7692 88.3333
#&amp;gt;  6    dino 38.7179 84.8718
#&amp;gt;  7    dino 35.6410 79.8718
#&amp;gt;  8    dino 33.0769 77.5641
#&amp;gt;  9    dino 28.9744 74.4872
#&amp;gt; 10    dino 26.1538 71.4103
#&amp;gt; # ... with 1,836 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can view all of the datasets at once using &lt;code&gt;facet_wrap&lt;/code&gt; in &lt;a href=&#34;http://ggplot2.tidyverse.org/&#34;&gt;&lt;strong&gt;ggplot2&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(datasaurus, aes(x = x, y = y)) +
  facet_wrap(~ dataset, nrow = 3) +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wjakethompson.github.io/post/datasaurus-dozen/figures/all-vis-1.png&#34; width=&#34;80%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Hard to believe all of these datasets have the same summary statistics!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;animating-the-plots&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Animating the plots&lt;/h2&gt;
&lt;p&gt;For a first pass at animating these datasets, I’ll use the &lt;strong&gt;gganimate&lt;/strong&gt; package. This works just like &lt;strong&gt;ggplot&lt;/strong&gt; code above, just with an added &lt;code&gt;frame&lt;/code&gt; aesthetic and no &lt;code&gt;facet_wrap&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(gganimate)

p &amp;lt;- ggplot(datasaurus, aes(x = x, y = y)) +
  geom_point(aes(frame = dataset))

animation::ani.options(interval = 1)
gganimate(p, title_frame = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure center&#34;&gt;
&lt;img src=&#34;https://wjakethompson.github.io/post/datasaurus-dozen/figures/gganimate-.gif&#34;&gt;
&lt;/div&gt;
&lt;p&gt;This is close, but not quite what I was looking for. This does indeed animate all of the datasets, but in order to duplicate the GIF above, I really want to see the points moving into their new positions for each dataset. To get this effect, I’ll use the &lt;strong&gt;tweenr&lt;/strong&gt; package. &lt;strong&gt;tweenr&lt;/strong&gt; takes in a list of dataframes, and then interpolates the transitions between the states.&lt;/p&gt;
&lt;p&gt;First, I’ll create a list of the datasets.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_datasaurus &amp;lt;- datasaurus %&amp;gt;%
  group_by(dataset) %&amp;gt;%
  nest() %&amp;gt;%
  add_row(dataset = &amp;quot;dino&amp;quot;, data = list(.$data[[1]]))
n_datasaurus
#&amp;gt; # A tibble: 14 x 2
#&amp;gt;       dataset               data
#&amp;gt;        &amp;lt;fctr&amp;gt;             &amp;lt;list&amp;gt;
#&amp;gt;  1       dino &amp;lt;tibble [142 x 2]&amp;gt;
#&amp;gt;  2       away &amp;lt;tibble [142 x 2]&amp;gt;
#&amp;gt;  3    h_lines &amp;lt;tibble [142 x 2]&amp;gt;
#&amp;gt;  4    v_lines &amp;lt;tibble [142 x 2]&amp;gt;
#&amp;gt;  5    x_shape &amp;lt;tibble [142 x 2]&amp;gt;
#&amp;gt;  6       star &amp;lt;tibble [142 x 2]&amp;gt;
#&amp;gt;  7 high_lines &amp;lt;tibble [142 x 2]&amp;gt;
#&amp;gt;  8       dots &amp;lt;tibble [142 x 2]&amp;gt;
#&amp;gt;  9     circle &amp;lt;tibble [142 x 2]&amp;gt;
#&amp;gt; 10   bullseye &amp;lt;tibble [142 x 2]&amp;gt;
#&amp;gt; 11   slant_up &amp;lt;tibble [142 x 2]&amp;gt;
#&amp;gt; 12 slant_down &amp;lt;tibble [142 x 2]&amp;gt;
#&amp;gt; 13 wide_lines &amp;lt;tibble [142 x 2]&amp;gt;
#&amp;gt; 14       dino &amp;lt;tibble [142 x 2]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I’ve also added the dino dataset again at the bottom so that the GIF with start and end with that dataset, making it seamless. I’ll then use &lt;code&gt;tween_states&lt;/code&gt;, sending it the list of dataframes, and specifying the length of each state and transitions (I had to play around a bit with the numbers until I was happy with the final animation).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tween_datasaurus &amp;lt;- tween_states(n_datasaurus$data, tweenlength = 1,
  statelength = 0.5, ease = &amp;quot;sine-out&amp;quot;, nframe = 200) %&amp;gt;%
  as.tibble()
tween_datasaurus
#&amp;gt; # A tibble: 28,400 x 3
#&amp;gt;          x       y .frame
#&amp;gt;      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;  &amp;lt;int&amp;gt;
#&amp;gt;  1 55.3846 97.1795      1
#&amp;gt;  2 51.5385 96.0256      1
#&amp;gt;  3 46.1538 94.4872      1
#&amp;gt;  4 42.8205 91.4103      1
#&amp;gt;  5 40.7692 88.3333      1
#&amp;gt;  6 38.7179 84.8718      1
#&amp;gt;  7 35.6410 79.8718      1
#&amp;gt;  8 33.0769 77.5641      1
#&amp;gt;  9 28.9744 74.4872      1
#&amp;gt; 10 26.1538 71.4103      1
#&amp;gt; # ... with 28,390 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This creates a new dataframe with the added &lt;code&gt;.frame&lt;/code&gt; variable. I can then use the same &lt;strong&gt;gganimate&lt;/strong&gt; code from above, just specifying &lt;code&gt;.frame&lt;/code&gt; as the frame aesthetic instead of &lt;code&gt;dataset&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- ggplot(tween_datasaurus, aes(x = x, y = y)) +
  geom_point(aes(frame = .frame))

animation::ani.options(interval = 1 / 15)
gganimate(p, title_frame = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure center&#34;&gt;
&lt;img src=&#34;https://wjakethompson.github.io/post/datasaurus-dozen/figures/tweenr-animation-.gif&#34;&gt;
&lt;/div&gt;
&lt;p&gt;And there you have it! Now we can see all of the points moving between each dataset!&lt;/p&gt;
&lt;p&gt;&lt;details&gt;&lt;summary&gt;Session info&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::session_info()
#&amp;gt;  setting  value                       
#&amp;gt;  version  R version 3.4.0 (2017-04-21)
#&amp;gt;  system   x86_64, linux-gnu           
#&amp;gt;  ui       X11                         
#&amp;gt;  language (EN)                        
#&amp;gt;  collate  en_US.UTF-8                 
#&amp;gt;  tz       Etc/UTC                     
#&amp;gt;  date     2017-05-29                  
#&amp;gt; 
#&amp;gt;  package    * version    date       source                            
#&amp;gt;  animation  * 2.5        2017-05-26 Github (yihui/animation@98edc0d)  
#&amp;gt;  assertthat   0.2.0      2017-04-11 cran (@0.2.0)                     
#&amp;gt;  backports    1.1.0      2017-05-22 cran (@1.1.0)                     
#&amp;gt;  base       * 3.4.0      2017-04-21 local                             
#&amp;gt;  blogdown     0.0.41     2017-05-26 Github (rstudio/blogdown@a367835) 
#&amp;gt;  bookdown     0.4        2017-05-26 Github (rstudio/bookdown@b9f0e40) 
#&amp;gt;  broom        0.4.2      2017-02-13 cran (@0.4.2)                     
#&amp;gt;  cellranger   1.1.0      2016-07-27 cran (@1.1.0)                     
#&amp;gt;  colorspace   1.3-2      2016-12-14 cran (@1.3-2)                     
#&amp;gt;  compiler     3.4.0      2017-04-21 local                             
#&amp;gt;  datasets   * 3.4.0      2017-04-21 local                             
#&amp;gt;  DBI          0.6-1      2017-04-01 cran (@0.6-1)                     
#&amp;gt;  devtools     1.13.1     2017-05-13 CRAN (R 3.4.0)                    
#&amp;gt;  digest       0.6.12     2017-01-27 CRAN (R 3.4.0)                    
#&amp;gt;  dplyr      * 0.5.0      2016-06-24 cran (@0.5.0)                     
#&amp;gt;  evaluate     0.10       2016-10-11 cran (@0.10)                      
#&amp;gt;  forcats    * 0.2.0      2017-01-23 cran (@0.2.0)                     
#&amp;gt;  foreign      0.8-67     2016-09-13 CRAN (R 3.4.0)                    
#&amp;gt;  gganimate  * 0.1.0.9000 2017-05-26 Github (dgrtwo/gganimate@bf82002) 
#&amp;gt;  ggplot2    * 2.2.1      2016-12-30 cran (@2.2.1)                     
#&amp;gt;  graphics   * 3.4.0      2017-04-21 local                             
#&amp;gt;  grDevices  * 3.4.0      2017-04-21 local                             
#&amp;gt;  grid         3.4.0      2017-04-21 local                             
#&amp;gt;  gtable       0.2.0      2016-02-26 cran (@0.2.0)                     
#&amp;gt;  haven        1.0.0      2016-09-23 cran (@1.0.0)                     
#&amp;gt;  hms          0.3        2016-11-22 cran (@0.3)                       
#&amp;gt;  htmltools    0.3.6      2017-04-28 cran (@0.3.6)                     
#&amp;gt;  httr         1.2.1      2016-07-03 CRAN (R 3.4.0)                    
#&amp;gt;  jsonlite     1.4        2017-04-08 CRAN (R 3.4.0)                    
#&amp;gt;  knitr      * 1.16       2017-05-18 cran (@1.16)                      
#&amp;gt;  labeling     0.3        2014-08-23 cran (@0.3)                       
#&amp;gt;  lattice      0.20-35    2017-03-25 CRAN (R 3.4.0)                    
#&amp;gt;  lazyeval     0.2.0      2016-06-12 cran (@0.2.0)                     
#&amp;gt;  lubridate    1.6.0      2016-09-13 cran (@1.6.0)                     
#&amp;gt;  magrittr     1.5        2014-11-22 cran (@1.5)                       
#&amp;gt;  memoise      1.1.0      2017-04-21 CRAN (R 3.4.0)                    
#&amp;gt;  methods      3.4.0      2017-04-21 local                             
#&amp;gt;  mnormt       1.5-5      2016-10-15 cran (@1.5-5)                     
#&amp;gt;  modelr       0.1.0      2016-08-31 cran (@0.1.0)                     
#&amp;gt;  munsell      0.4.3      2016-02-13 cran (@0.4.3)                     
#&amp;gt;  nlme         3.1-131    2017-02-06 CRAN (R 3.4.0)                    
#&amp;gt;  parallel     3.4.0      2017-04-21 local                             
#&amp;gt;  plyr         1.8.4      2016-06-08 cran (@1.8.4)                     
#&amp;gt;  psych        1.7.5      2017-05-03 cran (@1.7.5)                     
#&amp;gt;  purrr      * 0.2.2.2    2017-05-11 cran (@0.2.2.2)                   
#&amp;gt;  R6           2.2.1      2017-05-10 CRAN (R 3.4.0)                    
#&amp;gt;  Rcpp         0.12.11    2017-05-22 cran (@0.12.11)                   
#&amp;gt;  readr      * 1.1.1      2017-05-16 cran (@1.1.1)                     
#&amp;gt;  readxl       1.0.0      2017-04-18 cran (@1.0.0)                     
#&amp;gt;  reshape2     1.4.2      2016-10-22 cran (@1.4.2)                     
#&amp;gt;  rlang        0.1.1      2017-05-18 cran (@0.1.1)                     
#&amp;gt;  rmarkdown    1.5.9000   2017-05-26 Github (rstudio/rmarkdown@1ba5b8f)
#&amp;gt;  rprojroot    1.2        2017-01-16 cran (@1.2)                       
#&amp;gt;  rvest        0.3.2      2016-06-17 cran (@0.3.2)                     
#&amp;gt;  scales       0.4.1      2016-11-09 cran (@0.4.1)                     
#&amp;gt;  stats      * 3.4.0      2017-04-21 local                             
#&amp;gt;  stringi      1.1.5      2017-04-07 cran (@1.1.5)                     
#&amp;gt;  stringr      1.2.0      2017-02-18 cran (@1.2.0)                     
#&amp;gt;  tibble     * 1.3.1      2017-05-17 cran (@1.3.1)                     
#&amp;gt;  tidyr      * 0.6.3      2017-05-15 cran (@0.6.3)                     
#&amp;gt;  tidyverse  * 1.1.1      2017-01-27 cran (@1.1.1)                     
#&amp;gt;  tools        3.4.0      2017-04-21 local                             
#&amp;gt;  tweenr     * 0.1.5      2016-10-10 cran (@0.1.5)                     
#&amp;gt;  utils      * 3.4.0      2017-04-21 local                             
#&amp;gt;  withr        1.0.2      2016-06-20 CRAN (R 3.4.0)                    
#&amp;gt;  xml2         1.1.1      2017-01-24 cran (@1.1.1)                     
#&amp;gt;  yaml         2.1.14     2016-11-12 cran (@2.1.14)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/details&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Previewing the 2017 Men&#39;s NCAA Basketball Tournament</title>
      <link>https://wjakethompson.github.io/post/2017-03-13-march-madness-preview/</link>
      <pubDate>Mon, 13 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://wjakethompson.github.io/post/2017-03-13-march-madness-preview/</guid>
      <description>&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;


&lt;p&gt;March Madness officially tips off tomorrow with the First Four games in Dayton before the round of 64 begins on Thursday. In this post, we’ll look at each team’s chance of advancing and winning the national title. We’ll also look at who was help and hurt most by how the committee seeded the tournament.&lt;/p&gt;
&lt;p&gt;As always, the code and data for this post are available on my &lt;a href=&#34;https://github.com/wjakethompson/wjakethompson.github.io&#34;&gt;Github&lt;/a&gt; page.&lt;/p&gt;
&lt;div id=&#34;the-ratings&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Ratings&lt;/h2&gt;
&lt;p&gt;The team ratings come from my sports analytics website, &lt;a href=&#34;http://www.hawklytics.com/&#34;&gt;Hawklytics&lt;/a&gt;. Using the composite ratings, we can calculate the probability of any team beating another using the &lt;a href=&#34;https://en.wikipedia.org/wiki/Log5&#34;&gt;Log-5 formula&lt;/a&gt;. Using those probabilities, we can calculate the probability of any team advancing to each round.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(ggplot2)

bracket2017 &amp;lt;- readRDS(&amp;quot;datafiles/2017bracket.rds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;round-by-round-probabilities&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Round by Round Probabilities&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bracket2017 %&amp;gt;%
  select(Seed, School, Region, Round_3:Champion) %&amp;gt;%
  knitr::kable(digits = 3, col.names = gsub(&amp;quot;_&amp;quot;, &amp;quot; &amp;quot;, colnames(.)),
    align = &amp;quot;c&amp;quot;, booktabs = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;Seed&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;School&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Region&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Round 3&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Sweet 16&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Elite 8&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Final 4&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Final&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Champion&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Gonzaga&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;West&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.976&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.825&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.539&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.399&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.245&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.158&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;North Carolina&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.976&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.811&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.606&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.371&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.226&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.119&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Villanova&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.977&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.712&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.418&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.277&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.163&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.101&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Louisville&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Midwest&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.962&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.636&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.423&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.257&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.143&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.072&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;West Virginia&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;West&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.909&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.651&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.311&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.208&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.110&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.061&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Kentucky&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.952&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.571&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.375&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.210&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.119&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.058&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Kansas&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Midwest&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.958&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.703&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.415&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.224&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.114&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.052&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Virginia&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.875&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.521&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.267&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.165&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.090&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.051&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Duke&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.942&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.665&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.375&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.165&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.078&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.040&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Florida&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.866&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.433&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.201&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.114&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.057&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.030&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Wichita State&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.762&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.368&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.228&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.119&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.063&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.028&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Purdue&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Midwest&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.825&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.493&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.261&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.130&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.061&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.025&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Baylor&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.888&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.510&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.274&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.111&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.049&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.023&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Oregon&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Midwest&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.910&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.584&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.261&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.130&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.058&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.023&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Florida State&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;West&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.896&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.627&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.344&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.125&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.050&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.022&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Southern Methodist&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.787&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.417&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.219&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.086&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.037&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.017&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Saint Mary’s (CA)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;West&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.736&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.431&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.250&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.091&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.037&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.016&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Iowa State&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Midwest&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.770&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.401&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.197&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.091&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.039&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.015&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Butler&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.884&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.583&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.220&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.091&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.037&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.013&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;UCLA&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.907&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.485&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.190&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.081&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.034&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.012&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Arizona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;West&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.925&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.471&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.248&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.079&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.028&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.011&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Cincinnati&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.649&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.360&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.147&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.065&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.029&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.010&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Wisconsin&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.732&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.244&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.098&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.047&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.020&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.009&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Michigan&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Midwest&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.536&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.202&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.106&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.049&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.020&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.007&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Notre Dame&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;West&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.763&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.287&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.094&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.047&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.017&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.007&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Creighton&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Midwest&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.634&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.282&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.100&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.040&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.014&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.004&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Oklahoma State&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Midwest&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.464&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.160&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.078&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.034&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.013&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.004&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Miami (FL)&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Midwest&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.573&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.181&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.069&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.023&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.007&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.002&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Minnesota&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.602&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.258&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.071&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.022&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.006&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.002&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South Carolina&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.503&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.165&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.059&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.015&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.004&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Marquette&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.497&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.162&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.057&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.014&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.004&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Xavier&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;West&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.544&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.200&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.073&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.016&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.004&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Arkansas&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.532&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.104&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.042&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.011&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.003&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Kansas State&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.190&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.080&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.023&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.007&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.002&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Vanderbilt&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;West&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.507&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.088&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.025&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.009&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.002&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.001&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Michigan State&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Midwest&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.427&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.111&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.035&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.010&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.002&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Northwestern&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;West&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.493&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.084&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.023&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.008&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.002&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Maryland&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;West&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.456&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.151&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.050&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.009&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.002&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Rhode Island&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Midwest&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.366&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.120&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.029&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.008&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.002&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;11a&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Wake Forest&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.162&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.065&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.017&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.005&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.002&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Seton Hall&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.468&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.083&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.031&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.007&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.002&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Dayton&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.238&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.057&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.019&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.005&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.001&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Virginia Commonwealth&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;West&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.264&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.092&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.032&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.006&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.001&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Middle Tennessee&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.398&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.135&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.028&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.006&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.001&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;9&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Virginia Tech&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.268&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.043&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.009&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.002&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Nevada&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Midwest&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.230&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.061&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.014&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.003&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.001&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Providence&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.119&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.032&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.008&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.001&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Princeton&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;West&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.237&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.042&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.006&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.001&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Vermont&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Midwest&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.175&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.045&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.009&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.002&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;11a&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Southern California&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.094&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.023&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.005&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.001&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;North Carolina-Wilmington&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.125&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.025&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.004&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.001&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East Tennessee State&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.134&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.021&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.003&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Bucknell&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;West&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.091&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.020&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.002&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;14&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;New Mexico State&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.112&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.018&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.003&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;14&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Florida Gulf Coast&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;West&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.104&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.022&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.003&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;13&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Winthrop&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.116&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.024&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.002&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;14&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Iona&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Midwest&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.090&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.014&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.001&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;14&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Kent State&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.093&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.010&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.001&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;15&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Troy&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.058&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.007&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.001&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;15&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Northern Kentucky&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.048&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.004&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;15&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;North Dakota&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;West&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.075&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.006&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.001&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;North Carolina Central&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Midwest&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.031&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.004&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;15&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Jacksonville State&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Midwest&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.038&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.003&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South Dakota State&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;West&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.024&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.003&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Texas Southern&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.024&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.003&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;16a&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;New Orleans&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.013&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.001&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;16a&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;UC-Davis&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Midwest&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.011&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.001&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Mount St. Mary’s&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.010&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.001&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Gonzaga comes in as the favorite using my ratings with a 15.8% chance winning the title, followed by North Carolina and overall number 1 seed Villanova. Kansas, the other number 1 seed is the 7th most likely team to cut down the nets with a 5.2% chance.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;region-difficulty&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Region Difficulty&lt;/h2&gt;
&lt;p&gt;To see who got help and hurt by their seeding, we can first look at the talent level in each region. To do this, I’ll take the average offensive and defensive rating of all the teams in a region, and then calculate a net rating. To keep the extra teams playing in the First Four from bringing down the region average, I’ll keep only favorite from each of the play in games.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bracket2017 %&amp;gt;%
  filter(!grepl(&amp;quot;a&amp;quot;, Seed)) %&amp;gt;%
  group_by(Region) %&amp;gt;%
  summarize(Offense = mean(Offense), Defense = mean(Defense)) %&amp;gt;%
  mutate(Net = Offense - Defense) %&amp;gt;%
  arrange(desc(Net)) %&amp;gt;%
  knitr::kable(digits = 2, align = &amp;quot;c&amp;quot;, booktabs = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;Region&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Offense&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Defense&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Net&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;113.21&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;93.71&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;19.50&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;Midwest&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;113.43&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;94.62&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;18.81&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;West&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;112.41&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;94.76&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;17.66&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;South&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;112.24&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;94.95&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;17.29&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Villanova and Kansas, although the top two seeds in the tournament, weren’t given any favors, as they ended up in the two toughest regions in field. North Carolina, on the other hand, has the easiest region using these ratings.&lt;/p&gt;
&lt;p&gt;We can also look at the direct impact of the seeding process. Using the consensus bracket from the &lt;a href=&#34;http://www.bracketmatrix.com/&#34;&gt;Bracket Matrix&lt;/a&gt;, we can get a good gauge of where teams should have been seeded. I have calculated the probability of each team making the Final Four using the consensus bracket so we can compare these numbers to the probabilities from the real bracket.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;seeding &amp;lt;- bracket2017 %&amp;gt;%
  select(Seed, School, Region, Con_Final4, Final_4) %&amp;gt;%
  mutate(Change = Final_4 - Con_Final4) %&amp;gt;%
  select(-(Con_Final4:Final_4)) %&amp;gt;%
  arrange(desc(Change))

knitr::kable(head(seeding), digits = 3, align = &amp;quot;c&amp;quot;, booktabs = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;Seed&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;School&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Region&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Change&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;North Carolina&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.073&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Kansas&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Midwest&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.064&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Gonzaga&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;West&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.046&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;West Virginia&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;West&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.036&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Butler&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.033&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Louisville&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Midwest&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.033&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Although Kansas is in the second hardest region, they are 6.4% more likely to make the Final Four under the real bracket compared to the consensus bracket. This is because the bottom half of the Midwest region is much stronger relative to other regions, while the top half is slightly easier. Thus, the region as a whole is strong, but Kansas would only have to beat one of the teams from the bottom half in order to advance to the Final Four. Unsurprisingly, North Carolina, who is in the easiest region, benefits the most from the real seeding. They are 7.3% more likely to make the Final Four than when using the consensus bracket.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::kable(tail(seeding), digits = 3, align = &amp;quot;c&amp;quot;, booktabs = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;Seed&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;School&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Region&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Change&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Wisconsin&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.020&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Baylor&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.038&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Duke&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.054&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Florida&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.056&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Kentucky&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;South&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.059&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Villanova&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;East&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;-0.129&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;On the other end of the spectrum, Villanova was hurt the most by the real bracket by far. They are 12.9% less likely to make the Final Four than if the consensus bracket were used. In fact, this list is dominated by good teams who were all placed in the East region, and therefore have to fight each other to get out. The exception is Kentucky, who is 5.9% less likely to make the Final Four after drawing potential matchups with Wichita State, UCLA, and North Carolina.&lt;/p&gt;
&lt;p&gt;&lt;details&gt;&lt;summary&gt;Session info&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::session_info()
#&amp;gt; Session info -------------------------------------------------------------
#&amp;gt;  setting  value                       
#&amp;gt;  version  R version 3.4.0 (2017-04-21)
#&amp;gt;  system   x86_64, darwin15.6.0        
#&amp;gt;  ui       X11                         
#&amp;gt;  language (EN)                        
#&amp;gt;  collate  en_US.UTF-8                 
#&amp;gt;  tz       America/Chicago             
#&amp;gt;  date     2017-05-25
#&amp;gt; Packages -----------------------------------------------------------------
#&amp;gt;  package    * version    date       source                            
#&amp;gt;  assertthat   0.2.0      2017-04-11 CRAN (R 3.4.0)                    
#&amp;gt;  backports    1.0.5      2017-01-18 CRAN (R 3.4.0)                    
#&amp;gt;  base       * 3.4.0      2017-04-21 local                             
#&amp;gt;  bindr        0.1        2016-11-13 cran (@0.1)                       
#&amp;gt;  bindrcpp   * 0.1        2016-12-11 cran (@0.1)                       
#&amp;gt;  blogdown     0.0.41     2017-05-23 Github (rstudio/blogdown@a367835) 
#&amp;gt;  bookdown     0.4        2017-05-23 Github (rstudio/bookdown@b9f0e40) 
#&amp;gt;  codetools    0.2-15     2016-10-05 CRAN (R 3.4.0)                    
#&amp;gt;  colorspace   1.3-2      2016-12-14 CRAN (R 3.4.0)                    
#&amp;gt;  compiler     3.4.0      2017-04-21 local                             
#&amp;gt;  datasets   * 3.4.0      2017-04-21 local                             
#&amp;gt;  devtools     1.13.1     2017-05-13 CRAN (R 3.4.0)                    
#&amp;gt;  digest       0.6.12     2017-01-27 CRAN (R 3.4.0)                    
#&amp;gt;  dplyr      * 0.6.0      2017-05-23 Github (tidyverse/dplyr@c7ca374)  
#&amp;gt;  evaluate     0.10       2016-10-11 CRAN (R 3.4.0)                    
#&amp;gt;  ggplot2    * 2.2.1      2016-12-30 CRAN (R 3.4.0)                    
#&amp;gt;  glue         1.0.0      2017-04-17 cran (@1.0.0)                     
#&amp;gt;  graphics   * 3.4.0      2017-04-21 local                             
#&amp;gt;  grDevices  * 3.4.0      2017-04-21 local                             
#&amp;gt;  grid         3.4.0      2017-04-21 local                             
#&amp;gt;  gtable       0.2.0      2016-02-26 CRAN (R 3.4.0)                    
#&amp;gt;  highr        0.6        2016-05-09 CRAN (R 3.4.0)                    
#&amp;gt;  htmltools    0.3.6      2017-04-28 CRAN (R 3.4.0)                    
#&amp;gt;  knitr      * 1.16       2017-05-18 CRAN (R 3.4.0)                    
#&amp;gt;  lazyeval     0.2.0      2016-06-12 CRAN (R 3.4.0)                    
#&amp;gt;  magrittr     1.5        2014-11-22 CRAN (R 3.4.0)                    
#&amp;gt;  memoise      1.1.0      2017-04-21 CRAN (R 3.4.0)                    
#&amp;gt;  methods      3.4.0      2017-04-21 local                             
#&amp;gt;  munsell      0.4.3      2016-02-13 CRAN (R 3.4.0)                    
#&amp;gt;  plyr         1.8.4      2016-06-08 CRAN (R 3.4.0)                    
#&amp;gt;  R6           2.2.1      2017-05-10 cran (@2.2.1)                     
#&amp;gt;  Rcpp         0.12.11    2017-05-22 CRAN (R 3.4.0)                    
#&amp;gt;  rlang        0.1.1.9000 2017-05-23 Github (hadley/rlang@7c2f7e8)     
#&amp;gt;  rmarkdown    1.5.9000   2017-05-23 Github (rstudio/rmarkdown@54bf8fc)
#&amp;gt;  rprojroot    1.2        2017-01-16 CRAN (R 3.4.0)                    
#&amp;gt;  scales       0.4.1      2016-11-09 CRAN (R 3.4.0)                    
#&amp;gt;  stats      * 3.4.0      2017-04-21 local                             
#&amp;gt;  stringi      1.1.5      2017-04-07 CRAN (R 3.4.0)                    
#&amp;gt;  stringr      1.2.0      2017-02-18 CRAN (R 3.4.0)                    
#&amp;gt;  tibble       1.3.1      2017-05-17 CRAN (R 3.4.0)                    
#&amp;gt;  tools        3.4.0      2017-04-21 local                             
#&amp;gt;  utils      * 3.4.0      2017-04-21 local                             
#&amp;gt;  withr        1.0.2      2016-06-20 CRAN (R 3.4.0)                    
#&amp;gt;  yaml         2.1.14     2016-11-12 CRAN (R 3.4.0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/details&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Predicting the Winner of the 2017 Big 12/SEC Challenge</title>
      <link>https://wjakethompson.github.io/post/2017-01-27-big12-sec-simulation/</link>
      <pubDate>Fri, 27 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://wjakethompson.github.io/post/2017-01-27-big12-sec-simulation/</guid>
      <description>&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;


&lt;p&gt;The Big 12/SEC challenge tips off tomorrow. This will be the 4th year of this competition, and the Big 12 has &lt;a href=&#34;https://en.wikipedia.org/wiki/Big_12/SEC_Challenge#Series_History&#34;&gt;never lost&lt;/a&gt;. In this post, we’ll use a Monte Carlo simulation to estimate the Big 12’s chances of continuing this streak for another year.&lt;/p&gt;
&lt;p&gt;As always, the code and data for this post are available on my &lt;a href=&#34;https://github.com/wjakethompson/wjakethompson.github.io&#34;&gt;Github&lt;/a&gt; page.&lt;/p&gt;
&lt;div id=&#34;the-ratings&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Ratings&lt;/h2&gt;
&lt;p&gt;The team ratings come from my sports analytics website, &lt;a href=&#34;http://www.hawklytics.com/&#34;&gt;Hawklytics&lt;/a&gt;. We first have to adjust these ratings for home court advantage&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;, and then we can calculate the probability that the Big 12 will win each game using the &lt;a href=&#34;https://en.wikipedia.org/wiki/Log5&#34;&gt;Log-5 formula&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(ggplot2)
library(purrr)
library(readr)

big12sec &amp;lt;- read_csv(&amp;quot;datafiles/big12sec_2017.csv&amp;quot;, col_types = &amp;quot;ccn&amp;quot;)
big12sec
#&amp;gt; # A tibble: 10 x 3
#&amp;gt;               Home            Away Big12_Win
#&amp;gt;              &amp;lt;chr&amp;gt;           &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt;
#&amp;gt;  1   West Virginia       Texas A&amp;amp;M 0.9435388
#&amp;gt;  2        Oklahoma         Florida 0.2869581
#&amp;gt;  3       Tennessee    Kansas State 0.4904035
#&amp;gt;  4      Texas Tech Louisiana State 0.9121202
#&amp;gt;  5         Georgia           Texas 0.3345746
#&amp;gt;  6      Vanderbilt      Iowa State 0.6583537
#&amp;gt;  7  Oklahoma State        Arkansas 0.7371545
#&amp;gt;  8        Kentucky          Kansas 0.2822114
#&amp;gt;  9     Mississippi          Baylor 0.8425315
#&amp;gt; 10 Texas Christian          Auburn 0.8387957&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After accounting for the location of each game, we can see, for example, that Kansas has around a 28% chance of beating Kentucky, and Oklahoma State has a 74% chance of beating Arkansas. To get the expected number of wins for the Big 12, we can sum the probabilities of the Big 12 winning each game. Doing this, we get an expected number of wins of 6.33. This means that if we repeated the Big 12/SEC challenge multiple times, on average, the Big 12 would get about 6.33 wins.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;monte-carlo-simulation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Monte Carlo Simulation&lt;/h2&gt;
&lt;p&gt;It’s not possible for us to repeat the Big 12/SEC challenge multiple times in real life, but we can do this through a process called Monte Carlo simulation. In a Monte Carlo simulation we can generate data for an event multiple times, and then average the results over all replications. To illustrate we can simulate the winner of the Kansas vs. Kentucky game. According to the model, Kansas has a 28% chance of winning. We generate a random number between 0 and 1. If that number is less than 0.28, then Kansas is the winner of the simulation, otherwise, Kentucky is the winner. We do this for every game, and then count the number of winners that come from the Big 12 to determine which conference won the challenge (or if it was a tie). We then repeat this process over and over again to simulate many replications of the challenge.&lt;/p&gt;
&lt;p&gt;To enact this process in R, we’ll first need to define some functions. The first function will take in the probability of a team winning (in our case the Big 12 team), and return a 1 if that team wins, and a 0 otherwise.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_game &amp;lt;- function(prob) {
  ifelse(runif(1, min = 0, max = 1) &amp;lt; prob, 1, 0)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then define a function that takes in a vector of probabilities, and returns the number of wins.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_challenge &amp;lt;- function(prob_vec) {
  map_dbl(.x = prob_vec, .f = sim_game) %&amp;gt;% sum()
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we can use the &lt;code&gt;purrr&lt;/code&gt; package to simulate the Big 12/SEC challenge 10,000 times. Importantly, we need to set the random seed generator in order to make this analysis replicable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(71715)
num_sim &amp;lt;- 10000

challenge_wins &amp;lt;- map_dbl(.x = seq_len(num_sim), .f = function(x, prob_vec) {
  sim_challenge(prob_vec)
}, prob_vec = big12sec$Big12_Win)

sim_results &amp;lt;- data_frame(big12_wins = challenge_wins) %&amp;gt;%
  group_by(big12_wins) %&amp;gt;%
  summarize(n = n())
sim_results
#&amp;gt; # A tibble: 10 x 2
#&amp;gt;    big12_wins     n
#&amp;gt;         &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
#&amp;gt;  1          1     1
#&amp;gt;  2          2    12
#&amp;gt;  3          3   158
#&amp;gt;  4          4   626
#&amp;gt;  5          5  1785
#&amp;gt;  6          6  2878
#&amp;gt;  7          7  2755
#&amp;gt;  8          8  1380
#&amp;gt;  9          9   367
#&amp;gt; 10         10    38&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we would expect, the most common outcome was the Big 12 winning 6 games. This occured 2,878 times. The second most common outcome was the Big 12 winning 7 games, which occured 2,755 times. Also note that although there were 38 simulations where the Big 12 went undefeated, there no simulations where the Big 12 failed to win a game, and only 1 simulation where the Big 12 won a single game.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;plotting-the-results&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plotting the Results&lt;/h2&gt;
&lt;p&gt;Now that we have a distribution for the number of wins for the Big 12, we can plot the distribution using &lt;code&gt;ggplot2&lt;/code&gt;. First we assign a conference winner to each number of wins.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_results$winner &amp;lt;- case_when(
  sim_results$big12_wins &amp;lt; 5 ~ &amp;quot;SEC&amp;quot;,
  sim_results$big12_wins &amp;gt; 5 ~ &amp;quot;Big 12&amp;quot;,
  TRUE ~ &amp;quot;Tie&amp;quot;
)
sim_results
#&amp;gt; # A tibble: 10 x 3
#&amp;gt;    big12_wins     n winner
#&amp;gt;         &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;  &amp;lt;chr&amp;gt;
#&amp;gt;  1          1     1    SEC
#&amp;gt;  2          2    12    SEC
#&amp;gt;  3          3   158    SEC
#&amp;gt;  4          4   626    SEC
#&amp;gt;  5          5  1785    Tie
#&amp;gt;  6          6  2878 Big 12
#&amp;gt;  7          7  2755 Big 12
#&amp;gt;  8          8  1380 Big 12
#&amp;gt;  9          9   367 Big 12
#&amp;gt; 10         10    38 Big 12&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we can calulate the probability of each outcome.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;outcome &amp;lt;- sim_results %&amp;gt;%
  group_by(winner) %&amp;gt;%
  summarize(probability = sum(n) / num_sim) %&amp;gt;%
  mutate(probability = paste0(sprintf(&amp;quot;%0.1f&amp;quot;, probability * 100), &amp;quot;%&amp;quot;))
outcome
#&amp;gt; # A tibble: 3 x 2
#&amp;gt;   winner probability
#&amp;gt;    &amp;lt;chr&amp;gt;       &amp;lt;chr&amp;gt;
#&amp;gt; 1 Big 12       74.2%
#&amp;gt; 2    SEC        8.0%
#&amp;gt; 3    Tie       17.8%&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we put all of that information together and plot the distribution!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_results %&amp;gt;%
  mutate(n = n / num_sim) %&amp;gt;%
  ggplot(aes(x = factor(big12_wins, levels = 0:10), y = n, fill = winner)) +
  geom_col() +
  scale_x_discrete(drop = FALSE) +
  scale_y_continuous(breaks = seq(0, 1, 0.1),
    labels = paste0(seq(0, 100, 10), &amp;quot;%&amp;quot;)) +
  scale_fill_brewer(name = &amp;quot;Winner&amp;quot;, type = &amp;quot;qual&amp;quot;, palette = 7) +
  labs(title = &amp;quot;Big 12/SEC Challenge Probabilities&amp;quot;,
    subtitle = paste(paste0(outcome$winner, &amp;quot;: &amp;quot;, outcome$probability),
      collapse = &amp;quot;  |  &amp;quot;), x = &amp;quot;Big 12 Wins&amp;quot;, y = &amp;quot;Probability&amp;quot;) +
  theme_minimal() +
  theme(legend.position = &amp;quot;bottom&amp;quot;) +
  guides(fill = guide_legend(title.position = &amp;quot;top&amp;quot;, title.hjust = 0.5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wjakethompson.github.io/post/2017-01-27-big12-sec-simulation/figures/plot-1.png&#34; width=&#34;80%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The results of the simulation show that the Big 12 has about a 74% chance of winning the challenge and continuing their streak. I’ll be &lt;a href=&#34;https://twitter.com/jakethomp&#34;&gt;tweeting&lt;/a&gt; out updated probabilities throughout the day tomorrow as the games finish, so follow me there for updates!&lt;/p&gt;
&lt;p&gt;&lt;details&gt;&lt;summary&gt;Session info&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::session_info()
#&amp;gt; Session info -------------------------------------------------------------
#&amp;gt;  setting  value                       
#&amp;gt;  version  R version 3.4.0 (2017-04-21)
#&amp;gt;  system   x86_64, darwin15.6.0        
#&amp;gt;  ui       X11                         
#&amp;gt;  language (EN)                        
#&amp;gt;  collate  en_US.UTF-8                 
#&amp;gt;  tz       America/Chicago             
#&amp;gt;  date     2017-05-25
#&amp;gt; Packages -----------------------------------------------------------------
#&amp;gt;  package      * version    date       source                            
#&amp;gt;  animation    * 2.5        2017-03-30 CRAN (R 3.4.0)                    
#&amp;gt;  assertthat     0.2.0      2017-04-11 CRAN (R 3.4.0)                    
#&amp;gt;  backports      1.0.5      2017-01-18 CRAN (R 3.4.0)                    
#&amp;gt;  base         * 3.4.0      2017-04-21 local                             
#&amp;gt;  bindr          0.1        2016-11-13 cran (@0.1)                       
#&amp;gt;  bindrcpp     * 0.1        2016-12-11 cran (@0.1)                       
#&amp;gt;  blogdown       0.0.41     2017-05-23 Github (rstudio/blogdown@a367835) 
#&amp;gt;  bookdown       0.4        2017-05-23 Github (rstudio/bookdown@b9f0e40) 
#&amp;gt;  codetools      0.2-15     2016-10-05 CRAN (R 3.4.0)                    
#&amp;gt;  colorspace     1.3-2      2016-12-14 CRAN (R 3.4.0)                    
#&amp;gt;  compiler       3.4.0      2017-04-21 local                             
#&amp;gt;  datasets     * 3.4.0      2017-04-21 local                             
#&amp;gt;  devtools       1.13.1     2017-05-13 CRAN (R 3.4.0)                    
#&amp;gt;  digest         0.6.12     2017-01-27 CRAN (R 3.4.0)                    
#&amp;gt;  dplyr        * 0.6.0      2017-05-23 Github (tidyverse/dplyr@c7ca374)  
#&amp;gt;  evaluate       0.10       2016-10-11 CRAN (R 3.4.0)                    
#&amp;gt;  ggplot2      * 2.2.1      2016-12-30 CRAN (R 3.4.0)                    
#&amp;gt;  glue           1.0.0      2017-04-17 cran (@1.0.0)                     
#&amp;gt;  graphics     * 3.4.0      2017-04-21 local                             
#&amp;gt;  grDevices    * 3.4.0      2017-04-21 local                             
#&amp;gt;  grid           3.4.0      2017-04-21 local                             
#&amp;gt;  gtable         0.2.0      2016-02-26 CRAN (R 3.4.0)                    
#&amp;gt;  hms            0.3        2016-11-22 CRAN (R 3.4.0)                    
#&amp;gt;  htmltools      0.3.6      2017-04-28 CRAN (R 3.4.0)                    
#&amp;gt;  knitr        * 1.16       2017-05-18 CRAN (R 3.4.0)                    
#&amp;gt;  lazyeval       0.2.0      2016-06-12 CRAN (R 3.4.0)                    
#&amp;gt;  magrittr       1.5        2014-11-22 CRAN (R 3.4.0)                    
#&amp;gt;  memoise        1.1.0      2017-04-21 CRAN (R 3.4.0)                    
#&amp;gt;  methods        3.4.0      2017-04-21 local                             
#&amp;gt;  munsell        0.4.3      2016-02-13 CRAN (R 3.4.0)                    
#&amp;gt;  plyr           1.8.4      2016-06-08 CRAN (R 3.4.0)                    
#&amp;gt;  purrr        * 0.2.2.2    2017-05-11 CRAN (R 3.4.0)                    
#&amp;gt;  R6             2.2.1      2017-05-10 cran (@2.2.1)                     
#&amp;gt;  RColorBrewer   1.1-2      2014-12-07 CRAN (R 3.4.0)                    
#&amp;gt;  Rcpp           0.12.11    2017-05-22 CRAN (R 3.4.0)                    
#&amp;gt;  readr        * 1.1.0      2017-03-22 CRAN (R 3.4.0)                    
#&amp;gt;  rlang          0.1.1.9000 2017-05-23 Github (hadley/rlang@7c2f7e8)     
#&amp;gt;  rmarkdown      1.5.9000   2017-05-23 Github (rstudio/rmarkdown@54bf8fc)
#&amp;gt;  rprojroot      1.2        2017-01-16 CRAN (R 3.4.0)                    
#&amp;gt;  scales         0.4.1      2016-11-09 CRAN (R 3.4.0)                    
#&amp;gt;  stats        * 3.4.0      2017-04-21 local                             
#&amp;gt;  stringi        1.1.5      2017-04-07 CRAN (R 3.4.0)                    
#&amp;gt;  stringr        1.2.0      2017-02-18 CRAN (R 3.4.0)                    
#&amp;gt;  tibble         1.3.1      2017-05-17 CRAN (R 3.4.0)                    
#&amp;gt;  tools          3.4.0      2017-04-21 local                             
#&amp;gt;  utils        * 3.4.0      2017-04-21 local                             
#&amp;gt;  withr          1.0.2      2016-06-20 CRAN (R 3.4.0)                    
#&amp;gt;  yaml           2.1.14     2016-11-12 CRAN (R 3.4.0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/details&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;The home team’s offense is increased by 30% and defense is decreased by 30%, and the reverse is done for the away team.&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Making Win Probability Plots with ggplot2</title>
      <link>https://wjakethompson.github.io/post/2017-01-11-basketball-win-probability/</link>
      <pubDate>Wed, 11 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://wjakethompson.github.io/post/2017-01-11-basketball-win-probability/</guid>
      <description>&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;


&lt;p&gt;Last week I premiered my in game win probabilities for KU basketball. These have been available for a while on &lt;a href=&#34;http://www.hawklytics.com/winprob17&#34;&gt;Hawklytics&lt;/a&gt;, but were always made after the game rather than in real time. Now that they are going live, I thought it would helpful to document how these are made using R and the &lt;code&gt;ggplot2&lt;/code&gt; package.&lt;/p&gt;
&lt;div id=&#34;calculating-win-probability&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Calculating Win Probability&lt;/h2&gt;
&lt;p&gt;The win probabilities are based on the Elo ratings that I calculate for the &lt;a href=&#34;http://www.hawklytics.com/&#34;&gt;team ratings on Hawkytics&lt;/a&gt;. Elo ratings provide an estimate of team strength or ability &lt;em&gt;at the current point in time&lt;/em&gt;. This makes it straightforward to determine the ratings of each team on the day the game was played. For more about Elo ratings and how they are calculated go &lt;a href=&#34;https://en.wikipedia.org/wiki/Elo_rating_system&#34;&gt;here&lt;/a&gt;, or check out &lt;a href=&#34;http://fivethirtyeight.com/features/how-we-calculate-nba-elo-ratings/&#34;&gt;this explainer from FiveThirtyEight&lt;/a&gt;, which is what my Elo ratings are based off of.&lt;/p&gt;
&lt;p&gt;For this example, we’ll use the Kansas vs. Kansas State game on January 3, 2017. After giving KU a boost for home court advantage Kansas had a pre-game Elo rating of 2163, and Kansas State had an Elo rating of 1761. This difference in Elo ratings translates to Kansas being favored by ~15 points.&lt;/p&gt;
&lt;p&gt;We can likewise calculate the predicted point spread for every game in the data set (my data set includes all games between D1 opponents going back to 1980). This allows us to look at the difference between the predicted point spread, and the actual margin of victory. This prediction error is normally distributed with a mean of 0 and a standard deviation of 11.36. So the distribution of possible margins of victory for the Kansas vs. Kansas State game should look like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggplot2)
library(dplyr)

data_frame(
  x = seq(-50, 50, 0.5),
  y = dnorm(seq(-50, 50, 0.5), mean = -15, sd = 11.36)
) %&amp;gt;%
  mutate(winner = ifelse(x &amp;lt;= 0, &amp;quot;Kansas&amp;quot;, &amp;quot;Kansas State&amp;quot;)) %&amp;gt;%
  ggplot() +
  geom_ribbon(aes(x = x, ymin = 0, ymax = y, fill = winner)) +
  labs(x = &amp;quot;away team&amp;#39;s margin of victory&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wjakethompson.github.io/post/2017-01-11-basketball-win-probability/figures/initial_dist-1.png&#34; width=&#34;80%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The distribution peaks at -15, which is what we calculated as the most likely outcome. By convention, point spreads are given in terms of the home team, and a negative point spread means that team is the favorite. Because this game was played at Kansas, the point spread is &lt;strong&gt;Kansas -15&lt;/strong&gt;. If the game were being played at Kansas State, the point spread would be written as &lt;strong&gt;Kansas State + 15&lt;/strong&gt;. Because of this a negative margin of victory indicates a win for the home team. Therefore, a negative margin of victory is associated with Kansas winning, and a positive margin of victory is associated with Kansas State winning. To get the probability of Kansas winning, we can simply look at the proportion of the curve that is less than zero.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pnorm(0, mean = -15, sd = 11.36, lower.tail = TRUE)
#&amp;gt; [1] 0.906653&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So at the beginning of the game, we estimate Kansas to have a 90.7% chance of winning. As the game progresses, we calculate win probability in the exact same way, we just have to adjust for the current score and the amount of time remaining&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. The mean of the distribution gets defined as so that as the game progresses, the point spread gets less weight, and the current margin get more weight.&lt;/p&gt;
&lt;span class=&#34;math display&#34; id=&#34;eq:mu&#34;&gt;\[\begin{equation}
\mu = \left(point\_spread\  \times\ \frac{minutes\_remain}{40}\right) + \left(margin \times \frac{minutes\_played}{40}\right)
\tag{1}
\end{equation}\]&lt;/span&gt;
&lt;p&gt;Similarly, the standard deviation is adjusted so that the distribution gets more narrow as the game progresses.&lt;/p&gt;
&lt;span class=&#34;math display&#34; id=&#34;eq:sigma&#34;&gt;\[\begin{equation}
\sigma = \frac{11.36}{\sqrt{\frac{40}{minutes\_remain}}}
\tag{2}
\end{equation}\]&lt;/span&gt;
&lt;p&gt;As the time remaining approaches 0, the denominator increases, making the standard deviation smaller and smaller.&lt;/p&gt;
&lt;p&gt;The only we need at this point is the score at each moment of the game, in order to calculate the mean and standard deviation. To get this information, we can scrape play-by-play data from the web.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scraping-play-by-play-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scraping Play-By-Play Data&lt;/h2&gt;
&lt;p&gt;There are many places we could scrape play-by-play information from, and many different packages we could use, but I’ll use the &lt;code&gt;rvest&lt;/code&gt; package to scrape play-by-play data from &lt;a href=&#34;http://www.espn.com/&#34;&gt;ESPN&lt;/a&gt;. With &lt;code&gt;rvest&lt;/code&gt;, getting the data from ESPN is fairly straightforward.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(rvest)

game_data &amp;lt;- read_html(&amp;quot;http://www.espn.com/mens-college-basketball/playbyplay?gameId=400916199&amp;quot;)
tables &amp;lt;- html_nodes(game_data, css = &amp;quot;table&amp;quot;)
tables &amp;lt;- html_table(tables, fill = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data we want is in tables 2 and 3, so we can select those and do some formatting.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;half_1 &amp;lt;- tables[[2]]
colnames(half_1) &amp;lt;- make.names(colnames(half_1))
half_1 &amp;lt;- half_1 %&amp;gt;%
  mutate(
    minute = gsub(&amp;quot;:.*&amp;quot;, &amp;quot;&amp;quot;, time) %&amp;gt;% as.numeric(),
    second = gsub(&amp;quot;.*:&amp;quot;, &amp;quot;&amp;quot;, time) %&amp;gt;% as.numeric(),
    min_played = (20 - (minute + (second / 60))),
    min_remain = 40 - min_played,
    SCORE = gsub(&amp;quot; &amp;quot;, &amp;quot;&amp;quot;, SCORE),
    away_score = gsub(&amp;quot;-.*&amp;quot;, &amp;quot;&amp;quot;, SCORE) %&amp;gt;% as.numeric(),
    home_score = gsub(&amp;quot;.*-&amp;quot;, &amp;quot;&amp;quot;, SCORE) %&amp;gt;% as.numeric(),
    period = &amp;quot;H1&amp;quot;
  ) %&amp;gt;%
  select(period, minute, second, min_played, min_remain, away_score,
    home_score, play = PLAY)

half_2 &amp;lt;- tables[[3]]
colnames(half_2) &amp;lt;- make.names(colnames(half_2))
half_2 &amp;lt;- half_2 %&amp;gt;%
  mutate(
    minute = gsub(&amp;quot;:.*&amp;quot;, &amp;quot;&amp;quot;, time) %&amp;gt;% as.numeric(),
    second = gsub(&amp;quot;.*:&amp;quot;, &amp;quot;&amp;quot;, time) %&amp;gt;% as.numeric(),
    min_played = 20 + (20 - (minute + (second / 60))),
    min_remain = 40 - min_played,
    SCORE = gsub(&amp;quot; &amp;quot;, &amp;quot;&amp;quot;, SCORE),
    away_score = gsub(&amp;quot;-.*&amp;quot;, &amp;quot;&amp;quot;, SCORE) %&amp;gt;% as.numeric(),
    home_score = gsub(&amp;quot;.*-&amp;quot;, &amp;quot;&amp;quot;, SCORE) %&amp;gt;% as.numeric(),
    period = &amp;quot;H2&amp;quot;
  ) %&amp;gt;%
  select(period, minute, second, min_played, min_remain, away_score,
    home_score, play = PLAY)

full_pbp &amp;lt;- bind_rows(list(half_1, half_2))
full_pbp&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;#&amp;gt; # A tibble: 336 x 8
#&amp;gt;    period minute second min_played min_remain away_score home_score
#&amp;gt;     &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
#&amp;gt;  1     H1     20      0  0.0000000   40.00000          0          0
#&amp;gt;  2     H1     19     50  0.1666667   39.83333          0          0
#&amp;gt;  3     H1     19     50  0.1666667   39.83333          0          0
#&amp;gt;  4     H1     19     43  0.2833333   39.71667          0          2
#&amp;gt;  5     H1     19     27  0.5500000   39.45000          0          2
#&amp;gt;  6     H1     19     27  0.5500000   39.45000          0          2
#&amp;gt;  7     H1     19     12  0.8000000   39.20000          0          2
#&amp;gt;  8     H1     19     12  0.8000000   39.20000          0          2
#&amp;gt;  9     H1     18     48  1.2000000   38.80000          2          2
#&amp;gt; 10     H1     18     33  1.4500000   38.55000          2          2
#&amp;gt; # ... with 326 more rows, and 1 more variables: play &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can create a data frame of all possible time points in the game, and fill in the scores.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyr)

minute &amp;lt;- 0:40
second &amp;lt;- 0:59
full_game &amp;lt;- crossing(minute, second) %&amp;gt;%
  arrange(desc(minute), desc(second)) %&amp;gt;%
  mutate(min_remain = minute + (second / 60), min_played = 40 - min_remain,
    home = 0, away = 0) %&amp;gt;%
  filter(min_remain &amp;lt;= 40)

for (i in seq_len(nrow(full_pbp))) {
  cur_time &amp;lt;- round(full_pbp$min_remain[i], digits = 2)
  cur_row &amp;lt;- which(round(full_game$min_remain, digits = 2) == cur_time)
  full_game$home[cur_row:nrow(full_game)] &amp;lt;- full_pbp$home_score[i]
  full_game$away[cur_row:nrow(full_game)] &amp;lt;- full_pbp$away_score[i]
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we have the data we want in a workable form, we can move on to calculating the win probabilities and creating the plot.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;plotting-the-win-probabilities&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plotting the Win Probabilities&lt;/h2&gt;
&lt;p&gt;The first thing we have to do is calculate the mean and standard deviation of the distribution at every second of the game, and the corresponding win probability.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;full_game &amp;lt;- full_game %&amp;gt;%
  mutate(
    away_margin = away - home,
    mean = (-15 * (min_remain / 40)) + (away_margin * (min_played / 40)),
    sd = 11.36 / sqrt(40 / min_remain),
    home_winprob = pnorm(0, mean = mean, sd = sd, lower.tail = TRUE),
    away_winprob = 1 - home_winprob
  )
full_game
#&amp;gt; # A tibble: 2,401 x 11
#&amp;gt;    minute second min_remain min_played  home  away away_margin      mean
#&amp;gt;     &amp;lt;int&amp;gt;  &amp;lt;int&amp;gt;      &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
#&amp;gt;  1     40      0   40.00000 0.00000000     0     0           0 -15.00000
#&amp;gt;  2     39     59   39.98333 0.01666667     0     0           0 -14.99375
#&amp;gt;  3     39     58   39.96667 0.03333333     0     0           0 -14.98750
#&amp;gt;  4     39     57   39.95000 0.05000000     0     0           0 -14.98125
#&amp;gt;  5     39     56   39.93333 0.06666667     0     0           0 -14.97500
#&amp;gt;  6     39     55   39.91667 0.08333333     0     0           0 -14.96875
#&amp;gt;  7     39     54   39.90000 0.10000000     0     0           0 -14.96250
#&amp;gt;  8     39     53   39.88333 0.11666667     0     0           0 -14.95625
#&amp;gt;  9     39     52   39.86667 0.13333333     0     0           0 -14.95000
#&amp;gt; 10     39     51   39.85000 0.15000000     0     0           0 -14.94375
#&amp;gt; # ... with 2,391 more rows, and 3 more variables: sd &amp;lt;dbl&amp;gt;,
#&amp;gt; #   home_winprob &amp;lt;dbl&amp;gt;, away_winprob &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then put the data into long format using the &lt;code&gt;gather&lt;/code&gt; function from the &lt;code&gt;tidyr&lt;/code&gt; package, and plot the probabilities!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;full_game %&amp;gt;%
  gather(team, winprob, home_winprob:away_winprob) %&amp;gt;%
  ggplot(aes(x = min_played, y = winprob, color = team)) +
  geom_line()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wjakethompson.github.io/post/2017-01-11-basketball-win-probability/figures/winprob_plot-1.png&#34; width=&#34;80%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Looks pretty good! We can see that even though Kansas wasn’t leading on the score board the whole game, they were always favored to win. Although Kansas State was able to make it close at the end of the game. Now we can add some formatting to make it look prettier.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;full_game %&amp;gt;%
  gather(team, winprob, home_winprob:away_winprob) %&amp;gt;%
  ggplot(aes(x = min_played, y = winprob, color = team)) +
  geom_line(size = 1) +
  scale_color_manual(values = c(&amp;quot;#512888&amp;quot;, &amp;quot;#0051BA&amp;quot;),
    labels = c(&amp;quot;Kansas State&amp;quot;, &amp;quot;Kansas&amp;quot;)) +
  geom_hline(aes(yintercept = 0.5), color = &amp;quot;#000000&amp;quot;, linetype = &amp;quot;dashed&amp;quot;,
    size = 1) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.1),
    labels = paste0(seq(0, 100, by = 10), &amp;quot;%&amp;quot;)) +
  scale_x_continuous(limits = c(0, 40), breaks = seq(0, 40, 4),
    labels = paste0(seq(40, 0, -4))) +
  labs(y = &amp;quot;Win Probability&amp;quot;, x = &amp;quot;Minutes Remaining&amp;quot;) +
  theme_minimal() +
  theme(legend.position = &amp;quot;bottom&amp;quot;, legend.title = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://wjakethompson.github.io/post/2017-01-11-basketball-win-probability/figures/final_plot-1.png&#34; width=&#34;80%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And there you have our final product! For future Kansas games, I will be &lt;a href=&#34;https://twitter.com/jakethomp&#34;&gt;tweeting out&lt;/a&gt; real time win probability graphs, and as always, previous games can be found on &lt;a href=&#34;http://www.hawklytics.com/winprob17&#34;&gt;Hawklytics&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bonus-animate-the-plots&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bonus: Animate the Plots&lt;/h2&gt;
&lt;p&gt;We could go one step further and animate the win probability plot using David Robinson’s &lt;a href=&#34;https://github.com/dgrtwo/gganimate&#34;&gt;&lt;code&gt;gganimate&lt;/code&gt;&lt;/a&gt; package. Our code looks the same, except we add a &lt;code&gt;frame&lt;/code&gt; aesthetic and the &lt;code&gt;gg_animate&lt;/code&gt; function at the end.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(gganimate)

p &amp;lt;- full_game %&amp;gt;%
  filter(second %% 20 == 0) %&amp;gt;%
  gather(team, winprob, home_winprob:away_winprob) %&amp;gt;%
  ggplot(aes(x = min_played, y = winprob, color = team, frame = min_played)) +
  geom_line(aes(cumulative = TRUE), size = 1) +
  scale_color_manual(values = c(&amp;quot;#512888&amp;quot;, &amp;quot;#0051BA&amp;quot;),
    labels = c(&amp;quot;Kansas State&amp;quot;, &amp;quot;Kansas&amp;quot;)) +
  geom_hline(aes(yintercept = 0.5), color = &amp;quot;#000000&amp;quot;, linetype = &amp;quot;dashed&amp;quot;,
    size = 1) +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.1),
    labels = paste0(seq(0, 100, by = 10), &amp;quot;%&amp;quot;)) +
  scale_x_continuous(limits = c(0, 40), breaks = seq(0, 40, 4),
    labels = paste0(seq(40, 0, -4))) +
  labs(y = &amp;quot;Win Probability&amp;quot;, x = &amp;quot;Minutes Remaining&amp;quot;) +
  theme_minimal() +
  theme(legend.position = &amp;quot;bottom&amp;quot;, legend.title = element_blank())

gganimate(p, interval = 0.2, title_frame = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure center&#34;&gt;
&lt;img src=&#34;https://wjakethompson.github.io/post/2017-01-11-basketball-win-probability/figures/ani_win-.gif&#34;&gt;
&lt;/div&gt;
&lt;p&gt;We could also animate the distribution to show exactly how the distribution is changing as we alter the mean and standard deviation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(purrr)

dist &amp;lt;- full_game %&amp;gt;%
  filter(second %% 20 == 0) %&amp;gt;%
  select(min_played, mean, sd) %&amp;gt;%
  as.list() %&amp;gt;%
  pmap_df(.l = ., .f = function(min_played, mean, sd) {
    data_frame(
      min_played = min_played,
      x = seq(-50, 50, 0.5),
      y = dnorm(seq(-50, 50, 0.5), mean = mean, sd = sd)
    ) %&amp;gt;%
      mutate(winner = ifelse(x &amp;lt;= 0, &amp;quot;home_win&amp;quot;, &amp;quot;away_win&amp;quot;))
  }) %&amp;gt;%
  mutate(min_played = round(min_played, digits = 2))

d &amp;lt;- ggplot(dist, aes(frame = min_played)) +
  geom_ribbon(aes(x = x, ymin = 0, ymax = y, fill = winner)) +
  scale_fill_manual(values = c(&amp;quot;#512888&amp;quot;, &amp;quot;#0051BA&amp;quot;),
    labels = c(&amp;quot;Kansas State&amp;quot;, &amp;quot;Kansas&amp;quot;)) +
  scale_x_continuous(breaks = seq(-50, 50, 10)) +
  labs(x = &amp;quot;Kansas State Margin of Victory&amp;quot;, title = &amp;quot;Minutes Played: &amp;quot;) +
  theme_minimal() +
  theme(legend.position = &amp;quot;bottom&amp;quot;, legend.title = element_blank())

gganimate(d, interval = 0.2)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure center&#34;&gt;
&lt;img src=&#34;https://wjakethompson.github.io/post/2017-01-11-basketball-win-probability/figures/ani_dist-.gif&#34;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;limitations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Limitations&lt;/h2&gt;
&lt;p&gt;There are several limitations to the way these win probabilities are calculated. First, the calculations assume that each team has a 50% chance of winning if the game goes into overtime. This is entirely accurate, as a team favored before the game would still be favored in overtime (but not by as much). Secondly, I don’t factor in who has possession of the ball. For example, if a team is down by 1 with 25 seconds to go and the ball, the model probably underestimates their chance of winning. In reality, when calculating the mean of the distribution, expected points on the current possession should be factored into the current margin. However, this model provides a nice starting place, and I think provides a pretty good general idea of how a teams probability of winning changed throughout the game.&lt;/p&gt;
&lt;p&gt;&lt;details&gt;&lt;summary&gt;Session info&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::session_info()
#&amp;gt;  setting  value                       
#&amp;gt;  version  R version 3.4.0 (2017-04-21)
#&amp;gt;  system   x86_64, darwin15.6.0        
#&amp;gt;  ui       X11                         
#&amp;gt;  language (EN)                        
#&amp;gt;  collate  en_US.UTF-8                 
#&amp;gt;  tz       America/Chicago             
#&amp;gt;  date     2017-05-25                  
#&amp;gt; 
#&amp;gt;  package    * version    date       source                            
#&amp;gt;  animation  * 2.5        2017-05-25 Github (yihui/animation@98edc0d)  
#&amp;gt;  assertthat   0.2.0      2017-04-11 CRAN (R 3.4.0)                    
#&amp;gt;  backports    1.0.5      2017-01-18 CRAN (R 3.4.0)                    
#&amp;gt;  base       * 3.4.0      2017-04-21 local                             
#&amp;gt;  bindr        0.1        2016-11-13 cran (@0.1)                       
#&amp;gt;  bindrcpp   * 0.1        2016-12-11 cran (@0.1)                       
#&amp;gt;  blogdown     0.0.41     2017-05-23 Github (rstudio/blogdown@a367835) 
#&amp;gt;  bookdown     0.4        2017-05-23 Github (rstudio/bookdown@b9f0e40) 
#&amp;gt;  broom        0.4.2      2017-02-13 CRAN (R 3.4.0)                    
#&amp;gt;  cellranger   1.1.0      2016-07-27 CRAN (R 3.4.0)                    
#&amp;gt;  codetools    0.2-15     2016-10-05 CRAN (R 3.4.0)                    
#&amp;gt;  colorspace   1.3-2      2016-12-14 CRAN (R 3.4.0)                    
#&amp;gt;  compiler     3.4.0      2017-04-21 local                             
#&amp;gt;  datasets   * 3.4.0      2017-04-21 local                             
#&amp;gt;  devtools     1.13.1     2017-05-13 CRAN (R 3.4.0)                    
#&amp;gt;  digest       0.6.12     2017-01-27 CRAN (R 3.4.0)                    
#&amp;gt;  dplyr      * 0.6.0      2017-05-23 Github (tidyverse/dplyr@c7ca374)  
#&amp;gt;  evaluate     0.10       2016-10-11 CRAN (R 3.4.0)                    
#&amp;gt;  forcats      0.2.0      2017-01-23 CRAN (R 3.4.0)                    
#&amp;gt;  foreign      0.8-67     2016-09-13 CRAN (R 3.4.0)                    
#&amp;gt;  gganimate  * 0.1.0.9000 2017-05-23 Github (dgrtwo/gganimate@bf82002) 
#&amp;gt;  ggplot2    * 2.2.1      2016-12-30 CRAN (R 3.4.0)                    
#&amp;gt;  glue         1.0.0      2017-04-17 cran (@1.0.0)                     
#&amp;gt;  graphics   * 3.4.0      2017-04-21 local                             
#&amp;gt;  grDevices  * 3.4.0      2017-04-21 local                             
#&amp;gt;  grid         3.4.0      2017-04-21 local                             
#&amp;gt;  gtable       0.2.0      2016-02-26 CRAN (R 3.4.0)                    
#&amp;gt;  haven        1.0.0      2016-09-23 CRAN (R 3.4.0)                    
#&amp;gt;  hms          0.3        2016-11-22 CRAN (R 3.4.0)                    
#&amp;gt;  htmltools    0.3.6      2017-04-28 CRAN (R 3.4.0)                    
#&amp;gt;  httr         1.2.1      2016-07-03 CRAN (R 3.4.0)                    
#&amp;gt;  jsonlite     1.4        2017-04-08 CRAN (R 3.4.0)                    
#&amp;gt;  knitr      * 1.16       2017-05-18 CRAN (R 3.4.0)                    
#&amp;gt;  labeling     0.3        2014-08-23 CRAN (R 3.4.0)                    
#&amp;gt;  lattice      0.20-35    2017-03-25 CRAN (R 3.4.0)                    
#&amp;gt;  lazyeval     0.2.0      2016-06-12 CRAN (R 3.4.0)                    
#&amp;gt;  lubridate    1.6.0      2016-09-13 CRAN (R 3.4.0)                    
#&amp;gt;  magrittr     1.5        2014-11-22 CRAN (R 3.4.0)                    
#&amp;gt;  memoise      1.1.0      2017-04-21 CRAN (R 3.4.0)                    
#&amp;gt;  methods      3.4.0      2017-04-21 local                             
#&amp;gt;  mnormt       1.5-5      2016-10-15 CRAN (R 3.4.0)                    
#&amp;gt;  modelr       0.1.0      2016-08-31 CRAN (R 3.4.0)                    
#&amp;gt;  munsell      0.4.3      2016-02-13 CRAN (R 3.4.0)                    
#&amp;gt;  nlme         3.1-131    2017-02-06 CRAN (R 3.4.0)                    
#&amp;gt;  parallel     3.4.0      2017-04-21 local                             
#&amp;gt;  plyr         1.8.4      2016-06-08 CRAN (R 3.4.0)                    
#&amp;gt;  psych        1.7.3.21   2017-03-22 CRAN (R 3.4.0)                    
#&amp;gt;  purrr      * 0.2.2.2    2017-05-11 CRAN (R 3.4.0)                    
#&amp;gt;  R6           2.2.1      2017-05-10 cran (@2.2.1)                     
#&amp;gt;  Rcpp         0.12.11    2017-05-22 CRAN (R 3.4.0)                    
#&amp;gt;  readr      * 1.1.0      2017-03-22 CRAN (R 3.4.0)                    
#&amp;gt;  readxl       1.0.0      2017-04-18 CRAN (R 3.4.0)                    
#&amp;gt;  reshape2     1.4.2      2016-10-22 CRAN (R 3.4.0)                    
#&amp;gt;  rlang        0.1.1.9000 2017-05-23 Github (hadley/rlang@7c2f7e8)     
#&amp;gt;  rmarkdown    1.5.9000   2017-05-23 Github (rstudio/rmarkdown@54bf8fc)
#&amp;gt;  rprojroot    1.2        2017-01-16 CRAN (R 3.4.0)                    
#&amp;gt;  rvest      * 0.3.2      2016-06-17 CRAN (R 3.4.0)                    
#&amp;gt;  scales       0.4.1      2016-11-09 CRAN (R 3.4.0)                    
#&amp;gt;  stats      * 3.4.0      2017-04-21 local                             
#&amp;gt;  stringi      1.1.5      2017-04-07 CRAN (R 3.4.0)                    
#&amp;gt;  stringr      1.2.0      2017-02-18 CRAN (R 3.4.0)                    
#&amp;gt;  tibble     * 1.3.1      2017-05-17 CRAN (R 3.4.0)                    
#&amp;gt;  tidyr      * 0.6.3      2017-05-15 CRAN (R 3.4.0)                    
#&amp;gt;  tidyverse  * 1.1.1      2017-01-27 CRAN (R 3.4.0)                    
#&amp;gt;  tools        3.4.0      2017-04-21 local                             
#&amp;gt;  utils      * 3.4.0      2017-04-21 local                             
#&amp;gt;  withr        1.0.2      2016-06-20 CRAN (R 3.4.0)                    
#&amp;gt;  xml2       * 1.1.1      2017-01-24 CRAN (R 3.4.0)                    
#&amp;gt;  yaml         2.1.14     2016-11-12 CRAN (R 3.4.0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/details&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;For details on the where these formulas come from, see Wayne Winston’s book, &lt;em&gt;&lt;a href=&#34;https://www.amazon.com/Mathletics-Gamblers-Enthusiasts-Mathematics-Basketball/dp/0691154589&#34;&gt;Mathletics&lt;/a&gt;&lt;/em&gt;, and &lt;a href=&#34;http://www.footballperspective.com/the-biggest-quarter-by-quarter-comebacks-since-1978/&#34;&gt;Neil Paine’s explainer&lt;/a&gt;.&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Evaluating Election Forecasts</title>
      <link>https://wjakethompson.github.io/post/2016-11-08-election-forecast-performance/</link>
      <pubDate>Tue, 08 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://wjakethompson.github.io/post/2016-11-08-election-forecast-performance/</guid>
      <description>&lt;!-- BLOGDOWN-HEAD --&gt;
&lt;!-- /BLOGDOWN-HEAD --&gt;


&lt;p&gt;After more than a year and a half, the 2016 presidential election is finally over, with Donald Trump &lt;a href=&#34;http://www.nytimes.com/elections/results/president&#34;&gt;projected to win&lt;/a&gt;. This is in contrast to many of the election forecasts, which almost unanimously predicted a &lt;a href=&#34;http://www.nytimes.com/interactive/2016/upshot/presidential-polls-forecast.html&#34;&gt;victory for Hillary Clinton&lt;/a&gt;. Now that the results are in, we can finally answer the question of who did the best (or least worst?) job of forecasting the election.&lt;/p&gt;
&lt;p&gt;There are several ways we could look at this question, but for the purpose of this analysis we’ll focus on two. The first is prediciton accuracy: how close were a model’s probabilities of winning each state to what actually happened? The second is model accuracy: if we assume that the model estimated probabilities were correct, how likely is it that we would see the outcome that was observed?&lt;/p&gt;
&lt;p&gt;Now, let’s see how some different forecasts performed.&lt;/p&gt;
&lt;div id=&#34;the-forecasts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Forecasts&lt;/h2&gt;
&lt;p&gt;For this analysis I’m going to focus on some of the more popular forecasts from this election cycle: the &lt;a href=&#34;http://www.nytimes.com/interactive/2016/upshot/presidential-polls-forecast.html&#34;&gt;New York Times&lt;/a&gt;, &lt;a href=&#34;http://projects.fivethirtyeight.com/2016-election-forecast/?ex_cid=rrpromo&#34;&gt;FiveThirtyEight&lt;/a&gt;, &lt;a href=&#34;http://elections.huffingtonpost.com/2016/forecast/president&#34;&gt;Huffington Post&lt;/a&gt;, &lt;a href=&#34;http://predictwise.com/&#34;&gt;PredictWise&lt;/a&gt;, the &lt;a href=&#34;http://election.princeton.edu/2012/09/29/the-short-term-presidential-predictor/&#34;&gt;Princeton Election Consortium&lt;/a&gt;, &lt;a href=&#34;https://twitter.com/PollSavvy&#34;&gt;Poll Savvy&lt;/a&gt;, &lt;a href=&#34;http://elections.dailykos.com/app/elections/2016&#34;&gt;Daily Kos&lt;/a&gt;, &lt;a href=&#34;http://www.thecrosstab.com/2016/11/07/final-2016-forecast/&#34;&gt;Crosstab&lt;/a&gt;, and &lt;a href=&#34;http://www.slate.com/features/pkremp_forecast/report.html&#34;&gt;Slate (Pierre-Antoine Kremp)&lt;/a&gt;. Additionally, I’ll include the 2012 electoral map as a baseline. A special thanks to &lt;a href=&#34;http://dannypage.github.io/&#34;&gt;Danny Page&lt;/a&gt; who compiled all of the &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1WZdg3fcvK_J-XRtN8WpEb9nRB9nF-gi6DRDYINku_PU/edit#gid=0&#34;&gt;data&lt;/a&gt;, and whose analysis on the different forecasts can be found &lt;a href=&#34;https://twitter.com/dannypage&#34;&gt;here&lt;/a&gt;. As always, the code and data for this post can be found on &lt;a href=&#34;https://github.com/wjakethompson/wjakethompson.github.io&#34;&gt;my github&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;prediction-accuracy&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Prediction Accuracy&lt;/h2&gt;
&lt;p&gt;For the first part of the analysis, we’ll look at how close the predictions were in each state for each model. To do this, we’ll use the &lt;a href=&#34;https://en.wikipedia.org/wiki/Brier_score&#34;&gt;Brier Score&lt;/a&gt;, which is a measure of how close predicted probabilities were to an observed event. The formula for the Brier Score is given as&lt;/p&gt;
&lt;span class=&#34;math display&#34; id=&#34;eq:brier&#34;&gt;\[\begin{equation}
BS = \frac{1}{N} \displaystyle\sum_{t=1}^{N}(f_t-o_t)^2
\tag{1}
\end{equation}\]&lt;/span&gt;
&lt;p&gt;where “N” is the total number of predictions, “f” is the predicted probability of the event, and “o” is the observed outcome. Thus, a perfect prediction (e.g., a probability of 1.0 and the event actually occuring, or a probability of 0.0 and the event not occuring) would result in a Brier Score of 0, and the worst possible score is 1. For example if a model predicted Hillary Clinton had an 87 percent chance of winning a state, and she ended up winning that state, that part of the Brier score would be calculated as &lt;span class=&#34;math inline&#34;&gt;\((0.87 - 1)^2 = 0.0169\)&lt;/span&gt;. Because the probability is close to 1, and the event happened, the Brier Score is low, indicating high prediction accuracy. In contrast, if Clinton were to lose that state, the Brier score would be &lt;span class=&#34;math inline&#34;&gt;\((0.87 - 0)^2 = 0.7569\)&lt;/span&gt;, a relatively large number indicating a bad prediction. For any given model then, we can add up these prediction errors for each state, and then divide by the total number of predictions to get an overall Brier Score for each model:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Forecast&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Brier Score&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;FiveThirtyEight&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.066&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Crosstab&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.070&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Slate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.076&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;PredictWise&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.076&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;New York Times&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.076&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Princeton&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.077&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Poll Savvy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.080&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Daily Kos&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.080&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Huffington Post&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.090&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;2012 Map&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.125&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Using this method, all models out perform the 2012 map, as we would expect. Nate Silver and FiveThirtyEight come out on top, with the lowest average prediction error. However, we can also look at a weighted Brier Score. Maybe we care more about an error if there were a large number of electoral votes were at stake. For example, predicting Florida incorrectly has more implications for who wins the presidency than predicting North Dakota incorrectly. We can add a weight to the Brier Score formula by multiplying the electoral votes by the error.&lt;/p&gt;
&lt;span class=&#34;math display&#34; id=&#34;eq:brier-wt&#34;&gt;\[\begin{equation}
BS = BS = \displaystyle\sum_{t=1}^{N}EV_t(f_t-o_t)^2
\tag{2}
\end{equation}\]&lt;/span&gt;
&lt;p&gt;For this method, we are just summing all of the weighted prediction errors, rather than taking the average. This means that the Brier score is equivalent to the number of electoral votes that were incorrectly predicted. Thus, a perfect score is still 0, but the worst possible score is 538, if every state were incorrectly predicted with a probability of 0 or 1.&lt;/p&gt;
&lt;p&gt;Using the weighted Brier Score, we see similar results.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Forecast&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Brier Score&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Weighted Brier&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;FiveThirtyEight&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.066&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;48.793&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Crosstab&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.070&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;59.601&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Princeton&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.077&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;62.813&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;New York Times&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.076&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;64.643&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Poll Savvy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.080&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;64.668&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Slate&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.076&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;65.038&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;PredictWise&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.076&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;68.132&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Daily Kos&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.080&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;69.283&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Huffington Post&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.090&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;80.722&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;2012 Map&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.125&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;100.000&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;FiveThirtyEight again performs the best, prediting the equivalent of about 49 electoral votes incorrectly, a full 11 electoral votes better than the second best performing model (Crosstab). Compare this to the 2012 map, which would have predicted 100 electoral votes incorrectly. So using either the raw or weighted Brier Score, all models performed better than our baseline of the 2012 map, and FiveThirtyEight performed better than all other models.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-accuracy&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model Accuracy&lt;/h2&gt;
&lt;p&gt;To get an idea of the model accuracy, we can simulate the election thousands of times for each model, assuming that their estimated probabilities are the true probabilities in each case. For each simulation we will then get a distribution of the number of states each model should expect to predict incorrectly. We will then compare this expected number of incorrect picks to the observed number. A large discrepancy between the expected and observed mean that the model’s probabilites were not consistent with the observed data, indicating poor model accuracy.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wjakethompson.github.io/post/2016-11-08-election-forecast-performance/figures/sim-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the plot above, the red line indicates the number of states the model actually predicted incorrectly. All of the model incorrectly predicted 5 states, with the exception of Princeton, which incorrectly predicted only 4 states. However, we see that we would expect most of the models to get less states incorrect than that, given their estimated probabilities. For example, we would expect Huffington Post to miss 1.25 states on average, and FiveThirtyEight to miss 5.37 states on average, given their probabilities in each state. So the Huffington Post’s model was not as accurate as FiveThirtyEight’s.&lt;/p&gt;
&lt;p&gt;This occurs because Huffington Post had less uncertainty in their model, so there were fewer states that their model thought had a chance to flip, and thus result in an incorrect prediction. FiveThirtyEight had more uncertainty, meaning that on average, their model would expect to get more states wrong, because there was less certainty in who would win each state. As it turns out, this election was a lot more uncertain than people thought, which is why FiveThirtyEight’s expected value is closer to what was observed than other models that had less uncertainty.&lt;/p&gt;
&lt;p&gt;We can quantify how wrong a model was by looking at the proportion of simualtions that resulted in more incorrect picks than what was observed (the p-value). This can be thought of as the probability of incorrectly picking the observed number, if your probabilities were correct. Traditionally, p-values less than 0.05 are used to indicate poor model fit. In the graphic, we can see that only FiveThirtyEight, the New York Times, Poll Savvy, and Princeton have p-values over 0.05. This means that we would conclude that the probabilities provided by these models are plausible, given the data we observed, whereas the other probabilities provided by the other models would be rejected.&lt;/p&gt;
&lt;p&gt;There is one problem with this simulation that we could address to make our results more accurate. The simulation assumes that the results in each state are indepdent of each other. However, we know this is inaccurate, as many states tend to vote in the same way as other states with similar demographic characteristics. Practically, this means that the distributions in the above graphic aren’t as variable as they should be. The expected value won’t change much, but the distribution of plausible numbers of incorrect picks should get wider. Let’s test that and see if our conclusions are the same.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://wjakethompson.github.io/post/2016-11-08-election-forecast-performance/figures/corsim-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As expected, the distributions are much wider once we allow for correlated prediction errors, especially for the models that have more uncertainty in their predictions. Using the correlated errors, Princeton, Crosstab, Poll Savvy, the New York Times, and FiveThirtyEight all have p-values greater than 0.05, indicating that their estimated probabilities fit our observed data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Nate Silver and FiveThirtyEight received a lot of &lt;a href=&#34;http://www.huffingtonpost.com/entry/nate-silver-election-forecast_us_581e1c33e4b0d9ce6fbc6f7f?ncid=engmodushpmg00000004&#34;&gt;criticism&lt;/a&gt; for being bullish on Trump, but it looks like FiveThirtyEight gets to have the last laugh. Their model outperformed all of the other election forecasts that I analyzed: it had the best prediciton accuracy as measured by the raw and unweighted Brier Score, and it also had the best model accuracy, with simulations using their probabilities more closely matching the observed data than any other model. In an incredibly messing election, Nate Silver was the real winner.&lt;/p&gt;
&lt;p&gt;&lt;details&gt;&lt;summary&gt;Session info&lt;/summary&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::session_info()
#&amp;gt; Session info -------------------------------------------------------------
#&amp;gt;  setting  value                       
#&amp;gt;  version  R version 3.4.0 (2017-04-21)
#&amp;gt;  system   x86_64, darwin15.6.0        
#&amp;gt;  ui       X11                         
#&amp;gt;  language (EN)                        
#&amp;gt;  collate  en_US.UTF-8                 
#&amp;gt;  tz       America/Chicago             
#&amp;gt;  date     2017-05-25
#&amp;gt; Packages -----------------------------------------------------------------
#&amp;gt;  package    * version    date       source                            
#&amp;gt;  assertthat   0.2.0      2017-04-11 CRAN (R 3.4.0)                    
#&amp;gt;  backports    1.0.5      2017-01-18 CRAN (R 3.4.0)                    
#&amp;gt;  base       * 3.4.0      2017-04-21 local                             
#&amp;gt;  bindr        0.1        2016-11-13 cran (@0.1)                       
#&amp;gt;  bindrcpp   * 0.1        2016-12-11 cran (@0.1)                       
#&amp;gt;  blogdown     0.0.41     2017-05-23 Github (rstudio/blogdown@a367835) 
#&amp;gt;  bookdown     0.4        2017-05-23 Github (rstudio/bookdown@b9f0e40) 
#&amp;gt;  cellranger   1.1.0      2016-07-27 CRAN (R 3.4.0)                    
#&amp;gt;  codetools    0.2-15     2016-10-05 CRAN (R 3.4.0)                    
#&amp;gt;  colorspace   1.3-2      2016-12-14 CRAN (R 3.4.0)                    
#&amp;gt;  compiler     3.4.0      2017-04-21 local                             
#&amp;gt;  datasets   * 3.4.0      2017-04-21 local                             
#&amp;gt;  devtools     1.13.1     2017-05-13 CRAN (R 3.4.0)                    
#&amp;gt;  digest       0.6.12     2017-01-27 CRAN (R 3.4.0)                    
#&amp;gt;  dplyr      * 0.6.0      2017-05-23 Github (tidyverse/dplyr@c7ca374)  
#&amp;gt;  evaluate     0.10       2016-10-11 CRAN (R 3.4.0)                    
#&amp;gt;  ggplot2    * 2.2.1      2016-12-30 CRAN (R 3.4.0)                    
#&amp;gt;  glue         1.0.0      2017-04-17 cran (@1.0.0)                     
#&amp;gt;  graphics   * 3.4.0      2017-04-21 local                             
#&amp;gt;  grDevices  * 3.4.0      2017-04-21 local                             
#&amp;gt;  grid         3.4.0      2017-04-21 local                             
#&amp;gt;  gtable       0.2.0      2016-02-26 CRAN (R 3.4.0)                    
#&amp;gt;  highr        0.6        2016-05-09 CRAN (R 3.4.0)                    
#&amp;gt;  htmltools    0.3.6      2017-04-28 CRAN (R 3.4.0)                    
#&amp;gt;  knitr      * 1.16       2017-05-18 CRAN (R 3.4.0)                    
#&amp;gt;  labeling     0.3        2014-08-23 CRAN (R 3.4.0)                    
#&amp;gt;  lazyeval     0.2.0      2016-06-12 CRAN (R 3.4.0)                    
#&amp;gt;  magrittr     1.5        2014-11-22 CRAN (R 3.4.0)                    
#&amp;gt;  MASS       * 7.3-47     2017-02-26 CRAN (R 3.4.0)                    
#&amp;gt;  memoise      1.1.0      2017-04-21 CRAN (R 3.4.0)                    
#&amp;gt;  methods      3.4.0      2017-04-21 local                             
#&amp;gt;  munsell      0.4.3      2016-02-13 CRAN (R 3.4.0)                    
#&amp;gt;  pkgconfig    2.0.1      2017-03-21 cran (@2.0.1)                     
#&amp;gt;  plyr         1.8.4      2016-06-08 CRAN (R 3.4.0)                    
#&amp;gt;  purrr      * 0.2.2.2    2017-05-11 CRAN (R 3.4.0)                    
#&amp;gt;  R6           2.2.1      2017-05-10 cran (@2.2.1)                     
#&amp;gt;  Rcpp         0.12.11    2017-05-22 CRAN (R 3.4.0)                    
#&amp;gt;  readxl     * 1.0.0      2017-04-18 CRAN (R 3.4.0)                    
#&amp;gt;  rlang        0.1.1.9000 2017-05-23 Github (hadley/rlang@7c2f7e8)     
#&amp;gt;  rmarkdown    1.5.9000   2017-05-23 Github (rstudio/rmarkdown@54bf8fc)
#&amp;gt;  rprojroot    1.2        2017-01-16 CRAN (R 3.4.0)                    
#&amp;gt;  scales       0.4.1      2016-11-09 CRAN (R 3.4.0)                    
#&amp;gt;  stats      * 3.4.0      2017-04-21 local                             
#&amp;gt;  stringi      1.1.5      2017-04-07 CRAN (R 3.4.0)                    
#&amp;gt;  stringr      1.2.0      2017-02-18 CRAN (R 3.4.0)                    
#&amp;gt;  tibble       1.3.1      2017-05-17 CRAN (R 3.4.0)                    
#&amp;gt;  tools        3.4.0      2017-04-21 local                             
#&amp;gt;  utils      * 3.4.0      2017-04-21 local                             
#&amp;gt;  withr        1.0.2      2016-06-20 CRAN (R 3.4.0)                    
#&amp;gt;  yaml         2.1.14     2016-11-12 CRAN (R 3.4.0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;/details&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
